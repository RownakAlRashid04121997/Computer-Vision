import numpy as np
import os    #importing the python version
import pickle 
import matplotlib.pyplot as plt

def loadData(path):
    L_files = os.listdir(path='cifar-10-batches-py/') #stores the list of entries from the cifar-10 folder
    train = []   #creating train list
    train_labels = [] 
        
    print("The files ",L_files[1:6],"are being trained ")  #How many training datas are clooected will be showed
    
    for file in L_files[1:6]: 
        with open(path+file,'rb') as fldr: # with statement opens and closes file data automaticly,rb=read binary
            dict = pickle.load(fldr,encoding='bytes') 
            train.append(dict[b'data'])
            train_labels.append(dict[b'labels'])

    Dict_data = {} #creating dictionery
    Dict_data['train_data'] = np.reshape(np.array(train),newshape=(np.array(train).shape[0]*np.array(train).shape[1],np.array(train).shape[2]))
    Dict_data['train_labels'] = np.reshape(np.array(train_labels),newshape=(np.array(train_labels).shape[0]*np.array(train_labels).shape[1])) 
    return Dict_data  #The data of dictionary will be returned

Dataset = loadData(path='cifar-10-batches-py/')   #loading cifar-10

temp = Dataset['train_data'][15]  
label = Dataset['train_labels'][15] #Different data's can be visualized by changing the number in temp and label


R = temp[0:1024].reshape(32,32)
G = np.reshape(temp[1024:2048],newshape=(32,32))
B = np.reshape(temp[2048:],newshape=(32,32))
temp = np.dstack((R,G,B))  #Based upon the depth R,G,B will be joined ,d stands for depth
plt.imshow(temp)
plt.xticks([])
plt.yticks([])
plt.xlabel(label)
plt.show()

X_train, Y_train= Dataset['train_data'],Dataset['train_labels']

class kNearestNeighbour(object): #Classifier starts
    def __init__(self):
        pass
    
    def train(self,X,Y): #function is created so that knn can remember it's training data
        self.Xtr = X
        self.Ytr = Y
        
    def predict(self,X,k):
       
        Testing_samples = X.shape[0]
        
        Ypred = np.zeros(Testing_samples,dtype=self.Ytr.dtype)
        
        for i in range(Testing_samples):
            print("Testing sample = ",i,end="\r") #Samples are tested serially
            
            label_count = np.zeros(10,dtype=self.Ytr.dtype)    
            dist = np.sum(np.abs(X[i,:] - self.Xtr),axis=1) 
           
            idx = np.argpartition(dist,k)
            min_ind = idx[:k]
            
            for x in min_ind:
                label_count[int(self.Ytr[x])] +=1
            Ypred[i] = np.argmax(label_count)  #Maximum value at any index is returned using np.argmax() 
    
        return Ypred

Num_fold = 5
Num_train = 50000

k_choices = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]

if Num_train/Num_fold % Num_fold != 0.0:
    raise ValueError('Number of training samples are not evenly divisible by the number of folds.')
    

X_train_folds = np.split(X_train, Num_fold)
y_train_folds = np.split(Y_train, Num_fold)


k_to_accuracies = {} # Accuracy values that are found when using that value of k.


for k in k_choices:
    k_to_accuracies[k] = []
    
for idx in range(Num_fold):
    print("fold",idx,end="\n")  #To know the current number of fold
    
    X_train_set = np.concatenate((*X_train_folds[:idx], *X_train_folds[idx+1:]), axis=0)
    y_train_set = np.concatenate((*y_train_folds[:idx], *y_train_folds[idx+1:]), axis=0)
    X_validation_set = X_train_folds[idx]
    y_validation_set = y_train_folds[idx]   
    num_validation_set = X_validation_set.shape[0]

   
    knn = kNearestNeighbour()
    knn.train(X_train_set, y_train_set) #Knn is being trained
 
    
    for k in k_choices:
        print("k",k,end="\n")  #To know the current number of K
        
        y_validation_pred = knn.predict(X_validation_set,k)  # Predicts the labels for validation set
       
        accuracy = np.mean(y_validation_pred==y_validation_set)  # Checking accuracy

        k_to_accuracies[k].append(accuracy)
        

for k in sorted(k_to_accuracies):
    for accuracy in k_to_accuracies[k]:
        print('k = %d, accuracy = %f' % (k, accuracy))  # The accuracies are boing printed
    


for k in k_choices:
    accuracies = k_to_accuracies[k]
    print('k = %d, average accuracy = %f' % (k, np.average(accuracies)))  # The observations are being plotted
    plt.scatter([k] * len(accuracies), accuracies)
    

Accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])
Accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])
plt.errorbar(k_choices, Accuracies_mean, yerr=Accuracies_std)  #Error bars are plotted 
plt.title('cross validation on k')
plt.xlabel('k')
plt.ylabel('cross validation accuracy')
plt.show()