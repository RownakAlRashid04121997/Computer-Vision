{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os    \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    L_files = os.listdir(path='cifar-10-batches-py/') #stores the list of entries from the cifar-10 folder\n",
    "    train = []   #creating train list to store training data\n",
    "    train_labels = [] #creating train labels for storing names\n",
    "        \n",
    "    print(\"The files \",L_files[1:6],\"are being trained \")  #How many training datas are clooected will be showed\n",
    "    \n",
    "    for file in L_files[1:6]: \n",
    "        with open(path+file,'rb') as fldr: # with statement opens and closes file data automaticly,rb=read binary\n",
    "            dict = pickle.load(fldr,encoding='bytes') \n",
    "            train.append(dict[b'data'])\n",
    "            train_labels.append(dict[b'labels'])\n",
    "\n",
    "    Dict_data = {} #creating dictionery for storing train data and train label\n",
    "    Dict_data['train_data'] = np.reshape(np.array(train),newshape=(np.array(train).shape[0]*np.array(train).shape[1],np.array(train).shape[2]))\n",
    "    Dict_data['train_labels'] = np.reshape(np.array(train_labels),newshape=(np.array(train_labels).shape[0]*np.array(train_labels).shape[1])) \n",
    "    return Dict_data  #The data of dictionary will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files  ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5'] are being trained \n"
     ]
    }
   ],
   "source": [
    "Dataset = loadData(path='cifar-10-batches-py/')   #loading cifar-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset['train_data'].shape[0]  #The number of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = Dataset['train_data'][15]  #Data of image 15\n",
    "label = Dataset['train_labels'][15] #label of image 15\n",
    "\n",
    "\n",
    "R = temp[0:1024].reshape(32,32) #The image is converted into an 32*32 bot matrix,0 to 1024 is red\n",
    "G = np.reshape(temp[1024:2048],newshape=(32,32))#1024 to 1048 is blue\n",
    "B = np.reshape(temp[2048:],newshape=(32,32)) #From 2048 to rest is green\n",
    "temp = np.dstack((R,G,B))  #Based upon the depth R,G,B will be joined ,d stands for depth\n",
    "plt.imshow(temp)#tempis inparimeter in imshow\n",
    "plt.xticks([])#no tick in x\n",
    "plt.yticks([])#no tickin y\n",
    "plt.xlabel(label) #abel of the image will be shown in x axis\n",
    "plt.show()#for showing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train= Dataset['train_data'],Dataset['train_labels'] #For training of train data and train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class kNearestNeighbour(object): \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self,X,Y): \n",
    "        self.Xtr = X #remembers training data\n",
    "        self.Ytr = Y #remembers training labels\n",
    "        \n",
    "    def predict(self,X,k):\n",
    "       \n",
    "        Testing_samples = X.shape[0]\n",
    "        \n",
    "        Ypred = np.zeros(Testing_samples,dtype=self.Ytr.dtype)\n",
    "        \n",
    "        for i in range(Testing_samples):\n",
    "            print(\"Testing sample = \",i,end=\"\\r\") #Samples are tested serially\n",
    "            \n",
    "            label_count = np.zeros(10,dtype=self.Ytr.dtype)   #label_count's sise is the number of categories \n",
    "            dist = np.sum(np.abs(X[i,:] - self.Xtr),axis=1)  #Comparing pixels\n",
    "           \n",
    "            idx = np.argpartition(dist,k)\n",
    "            min_ind = idx[:k] # Finding the minimum index\n",
    "            \n",
    "            for x in min_ind:\n",
    "                label_count[int(self.Ytr[x])] +=1\n",
    "            Ypred[i] = np.argmax(label_count)  #Maximum value at any index is returned using np.argmax() \n",
    "    \n",
    "        return Ypred \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "k 1\n",
      "k 2ting sample =  9999\n",
      "k 3ting sample =  9999\n",
      "k 4ting sample =  9999\n",
      "k 5ting sample =  9999\n",
      "Testing sample =  5987\r"
     ]
    }
   ],
   "source": [
    "Num_fold = 5  # Number of folds=5\n",
    "Num_train = 50000\n",
    "\n",
    "k_choices = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] #The bigger size k_choices will be,the more accurate answer will come\n",
    "\n",
    "if Num_train/Num_fold % Num_fold != 0.0:\n",
    "    raise ValueError('Number of training samples are not evenly divisible by the number of folds.') #Samples can't be equally distributed in folds\n",
    "    \n",
    "\n",
    "X_train_folds = np.split(X_train, Num_fold) #datas are folded\n",
    "y_train_folds = np.split(Y_train, Num_fold) #labels are folded\n",
    "\n",
    "\n",
    "k_to_accuracies = {} # Accuracy values that are found when using that value of k.\n",
    "\n",
    "\n",
    "for k in k_choices:\n",
    "    k_to_accuracies[k] = []\n",
    "    \n",
    "for idx in range(Num_fold):\n",
    "    print(\"fold\",idx,end=\"\\n\")  #To know the current number of fold\n",
    "    \n",
    "    X_train_set = np.concatenate((*X_train_folds[:idx], *X_train_folds[idx+1:]), axis=0) #concatenates other folds exept the validation fold\n",
    "    y_train_set = np.concatenate((*y_train_folds[:idx], *y_train_folds[idx+1:]), axis=0)\n",
    "    X_validation_set = X_train_folds[idx] #The fold that is being validated\n",
    "    y_validation_set = y_train_folds[idx]   \n",
    "    num_validation_set = X_validation_set.shape[0]\n",
    "\n",
    "   \n",
    "    knn = kNearestNeighbour()\n",
    "    knn.train(X_train_set, y_train_set) #Knearestneighbour is being trained\n",
    " \n",
    "    \n",
    "    for k in k_choices:\n",
    "        print(\"k\",k,end=\"\\n\")  #To know the current number of K\n",
    "        \n",
    "        y_validation_pred = knn.predict(X_validation_set,k)  # Predicts the labels for validation set\n",
    "       \n",
    "        accuracy = np.mean(y_validation_pred==y_validation_set)  # Comparing validation prediction with validation set\n",
    "\n",
    "        k_to_accuracies[k].append(accuracy) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))  # The accuracies are being printed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    print('k = %d, average accuracy = %f' % (k, np.average(accuracies)))  # The average is printed\n",
    "    plt.scatter([k] * len(accuracies), accuracies) \n",
    "    \n",
    "\n",
    "Accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())]) #Mean of accuracies calculated \n",
    "Accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())]) #Standard Deviation is calculated\n",
    "plt.errorbar(k_choices, Accuracies_mean, yerr=Accuracies_std)  #Errorbars are plotted\n",
    "plt.title('cross validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('cross validation accuracy')\n",
    "plt.show()#The graph is shown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
